# nlp-topic-modeling-public
Final Project 

When it comes to text mining, dimensionality can be challenging. The ultimate goal of this project is to use machine learning and automatic natural language processing to create a probabilistic model for abstract themes. During our natural language processing courses, we had the opportunity to explore more in-depth the topic as well as have more information regarding Python, its libraries and Machine Learning.

To succeed in this project, we decided to work on Google Colab. This tool allowed us to work all at the same time in one environment. In addition, we use slack to communicate with each other. In addition, we used internet, and especially shared spaces such as GitHub or Kaggle.

A few weeks ago, we have been given a large CSV file, full of URLs. Once the dataset was cleaned, we decided to scrap the URLs in order to collect the information directly on the website. The challenge was to translate the information into an "attribute-value" array of data that is amenable to algorithmic processing while minimizing the loss of information. In order to build our complex dictionary, a process of tokenization has been used. Then we develop a probabilistic generative model to build the topics from our vocabularies. The model that has been used is Latent Dirichlet Allocation from Gensim library, ideal to model the process of data generation. The last step of our project was to optimize our model to obtain the best results.

In this report, we will explain more in depth the work that has been done with the data. In addition, the elaborate model and some experiments will be detailed. Finally, the results and possible further optimization will be highlighted. 
